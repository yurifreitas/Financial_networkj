# ============================================================
# üß† EtherSym Finance ‚Äî Carregamento simbi√≥tico robusto do modelo
# ============================================================
import os
import torch
from v1.network import RedeAvancada

STATE_PATH = "/home/yuri/Documents/code2/binance-model/backend/loader/estado_treinamento_finance.pth"


def carregar_modelo(device="cuda"):
    """
    Carrega o modelo de rede neural salvo em STATE_PATH com verifica√ß√£o simbi√≥tica:
    - Compat√≠vel com PyTorch >= 2.6 (safe_globals / weights_only)
    - Remove prefixos _orig_mod de checkpoints compilados
    - Detecta chaves ausentes/extras e faz diagn√≥sticos simbi√≥ticos
    """

    # Ajuste autom√°tico para CPU caso n√£o haja GPU
    if not torch.cuda.is_available() and device.startswith("cuda"):
        print("‚ö†Ô∏è GPU n√£o detectada ‚Äî usando CPU.")
        device = "cpu"

    # Verifica se o arquivo existe
    if not os.path.exists(STATE_PATH):
        raise FileNotFoundError(f"‚ùå Arquivo de estado n√£o encontrado em: {STATE_PATH}")

    print(f"üß© Carregando modelo simbi√≥tico de: {STATE_PATH}")

    # Inicializa estrutura base
    modelo = RedeAvancada(state_dim=10, n_actions=3).to(device)

    # =========================================================
    # üß¨ Carregamento seguro compat√≠vel (PyTorch 2.9)
    # =========================================================
    try:
        # Tenta modo padr√£o (weights_only=True)
        checkpoint = torch.load(STATE_PATH, map_location=device)
    except Exception as e1:
        print(f"‚ö†Ô∏è Falha no carregamento seguro ({type(e1).__name__}): {e1}")
        try:
            from torch.serialization import safe_globals
            with safe_globals([torch.torch_version.TorchVersion]):
                checkpoint = torch.load(STATE_PATH, map_location=device)
            print("üîí Carregado com safe_globals (TorchVersion liberado).")
        except Exception as e2:
            print(f"‚ö†Ô∏è Falha com safe_globals: {e2}")
            print("üö® Usando fallback com weights_only=False (modo legado, seguro se o arquivo √© seu).")
            checkpoint = torch.load(STATE_PATH, map_location=device, weights_only=False)

    # =========================================================
    # üîç Extrai o state_dict simbi√≥tico
    # =========================================================
    if isinstance(checkpoint, dict):
        state_dict = checkpoint.get("modelo") or checkpoint.get("state_dict") or checkpoint
    else:
        raise ValueError(f"‚ùå Checkpoint inv√°lido: tipo {type(checkpoint)}")

    # üîß Remove prefixo _orig_mod. se existir (gerado por torch.compile)
    clean_state = {k.replace("_orig_mod.", ""): v for k, v in state_dict.items()}

    # Diagn√≥stico de integridade
    model_keys = set(modelo.state_dict().keys())
    loaded_keys = set(clean_state.keys())
    missing = model_keys - loaded_keys
    unexpected = loaded_keys - model_keys

    if missing:
        print(f"‚ö†Ô∏è {len(missing)} camadas n√£o encontradas no arquivo (mantidas iniciais).")
    if unexpected:
        print(f"‚ö†Ô∏è {len(unexpected)} chaves extras detectadas (ignoradas).")

    # =========================================================
    # üíæ Aplica√ß√£o dos pesos
    # =========================================================
    modelo.load_state_dict(clean_state, strict=False)
    modelo.eval()

    # Diagn√≥stico final simbi√≥tico
    total_params = sum(p.numel() for p in modelo.parameters())
    trainable_params = sum(p.numel() for p in modelo.parameters() if p.requires_grad)
    print(f"‚úÖ Modelo restaurado com sucesso:")
    print(f"   ‚Ä¢ Par√¢metros totais:   {total_params:,}")
    print(f"   ‚Ä¢ Par√¢metros trein√°veis: {trainable_params:,}")
    print(f"   ‚Ä¢ Dispositivo ativo:   {device}")

    # Sanidade simbi√≥tica
    with torch.no_grad():
        mean_w = modelo.fc1.weight.abs().mean().item()
        if mean_w < 1e-5:
            print("‚ö†Ô∏è Aten√ß√£o: pesos parecem n√£o carregados (valores muito pr√≥ximos de zero).")

    return modelo


# ============================================================
# üîç Teste r√°pido
# ============================================================
if __name__ == "__main__":
    modelo = carregar_modelo()
