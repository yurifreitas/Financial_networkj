# =========================================================
# üåå EtherSym Finance ‚Äî main_v8f_full.py (vers√£o ultra-otimizada)
# =========================================================
# - Double DQN + N-Step + PER + Regress√£o cont√≠nua
# - AMP + GradClip + Homeostase + Poda + Regenera√ß√£o
# - Anneal Œµ, Temperatura e Œ≤-PER + Rollback simbi√≥tico
# - Otimiza√ß√µes: torch.compile (max-autotune), warmup CUDA,
#   infer√™ncia sem grad, libera√ß√£o VRAM/GC, checkpoints ass√≠ncronos
# =========================================================

import time, torch, gc, threading
from core.setup import setup_simbiotico
from core.scheduler import update_params
from core.collector import collect_step
from core.trainer import train_step
from core.checkpoints import check_vitoria, rollback_guard
from core.patrimonio import carregar_patrimonio_global, salvar_patrimonio_global
from core.maintenance import aplicar_poda, regenerar_sinapses, verificar_homeostase, homeostase_replay
from core.logger import log_status
from core.hyperparams import *
from memory import salvar_estado
import logging
# =========================================================
# üß† Setup simbi√≥tico inicial
# =========================================================
env, modelo, alvo, opt, replay, nbuf, scaler = setup_simbiotico()
best_global = carregar_patrimonio_global()

EPSILON, lr_now, temp_now, beta_per = 1.0, LR, TEMP_INI, BETA_PER_INI
ema_q = ema_r = 0.0
total_steps = 0
last_loss = 0.0
last_y_pred = 0.0
episodio = 0
cooldown_until = 0
rollbacks = 0
last_good = None
loop_start = time.perf_counter()

logging.info(f"üß† Iniciando treino simbi√≥tico | device={DEVICE.type} | patrim√¥nio inicial={best_global:.2f}")

# =========================================================
# üîÅ Loop principal (Epis√≥dios)
# =========================================================
while True:
    episodio += 1

    # üßπ Limpeza simbi√≥tica pr√©-reset
    try:
        torch.cuda.synchronize()
        torch.cuda.empty_cache()
        gc.collect()
    except Exception:
        pass

    # =========================================================
    # üîÑ Reset + Warmup CUDA simbi√≥tico
    # =========================================================
    s = env.reset()
    env.current_state = s
    try:
        with torch.inference_mode(), torch.amp.autocast("cuda"):
            _ = modelo(torch.tensor(s, device=DEVICE).unsqueeze(0))
        torch.cuda.synchronize()
        logging.info(f"üî• Warmup CUDA simbi√≥tico executado (epis√≥dio {episodio})")
    except Exception as e:
        logging.info(f"[WARN] Warmup simbi√≥tico falhou: {e}")

    # Estado inicial do epis√≥dio
    done = False
    total_reward_ep = 0.0
    capital = CAPITAL_INICIAL
    max_patrimonio = CAPITAL_INICIAL
    melhor_patrimonio_ep = CAPITAL_INICIAL
    ep_start = time.perf_counter()

    # =========================================================
    # üîÇ Loop interno (steps)
    # =========================================================
    while not done:
        total_steps += 1

        # üîß Atualiza√ß√£o simbi√≥tica de par√¢metros
        lr_now, EPSILON, temp_now, beta_per, eps_now = update_params(
            total_steps, lr_now, EPSILON, temp_now, beta_per, replay, opt
        )

        # üéØ Coleta de experi√™ncia simbi√≥tica (inference only)
        with torch.inference_mode():
            s, done, info, total_reward_ep = collect_step(
                env, modelo, DEVICE, eps_now, replay, nbuf, total_reward_ep
            )

        # üß† Treinamento simbi√≥tico (Q + Regress√£o)
        can_train = (len(replay) >= MIN_REPLAY) and (total_steps >= cooldown_until)
        if can_train:
            loss, ema_q, ema_r = train_step(modelo, alvo, opt, replay, scaler, ema_q, ema_r, total_steps)
            last_loss = loss if loss is not None else last_loss

            # ‚ö† Prote√ß√£o simbi√≥tica de rollback
            if rollback_guard(loss, total_steps, modelo, alvo, opt, replay, EPSILON):
                cooldown_until = total_steps + COOLDOWN_STEPS
                rollbacks += 1
                logging.info(f"‚ö† Rollback simbi√≥tico #{rollbacks} | cooldown at√© {cooldown_until}")

        # üèÜ Vit√≥ria simbi√≥tica (melhor patrim√¥nio)
        best_global = check_vitoria(
            info.get("patrimonio", 0.0),
            best_global, modelo, opt, replay,
            EPSILON, total_reward_ep
        )

        # üåø Homeostase e regenera√ß√£o
        if total_steps % PODA_EVERY == 0 and len(replay) >= MIN_REPLAY:
            taxa = aplicar_poda(modelo)
            regenerar_sinapses(modelo, taxa)
            verificar_homeostase(modelo, last_loss)
            logging.info(f"üåø Poda simbi√≥tica ‚Äî taxa={taxa*100:.2f}% | step={total_steps}")

        if total_steps % HOMEOSTASE_EVERY == 0:
            homeostase_replay(replay)

        modelo.verificar_homeostase(last_loss)

        # üîÑ Replay trimming (mant√©m leve)
        if total_steps % 20000 == 0 and len(replay) > MEMORIA_MAX * 0.9:
            try:
                replay.trim(capacity=int(MEMORIA_MAX * 0.85))
                logging.info(f"üßΩ Replay reduzido para {int(MEMORIA_MAX*0.85)} amostras")
            except Exception as e:
                logging.info(f"[WARN] Falha ao compactar replay: {e}")

        # üßæ Logging simbi√≥tico
        if total_steps % PRINT_EVERY == 0:
            energia = float(info.get("energia", 1.0))
            last_y_pred = float(info.get("ret", 0.0))
            log_status(
                episodio, total_steps,
                float(info.get("capital", capital)),
                float(info.get("patrimonio", 0.0)),
                float(info.get("max_patrimonio", max_patrimonio)),
                eps_now, temp_now, beta_per, lr_now,
                energia, last_y_pred, last_loss
            )
            loop_time = time.perf_counter() - loop_start
            logging.info(f"‚è±Ô∏è Tempo loop={loop_time:.3f}s | step={total_steps}")
            loop_start = time.perf_counter()

        # üíæ Checkpoint simbi√≥tico (thread)
        if total_steps % SAVE_EVERY == 0 and len(replay) >= MIN_REPLAY:
            threading.Thread(
                target=salvar_estado,
                args=(modelo, opt, replay, EPSILON, total_reward_ep),
                daemon=True
            ).start()
            logging.info(f"üíæ Checkpoint simbi√≥tico salvo | step={total_steps}")

        # üíæ Snapshot de rollback
        if total_steps % ROLLBACK_EVERY == 0 and len(replay) >= MIN_REPLAY:
            last_good = {
                "model": {k: v.detach().cpu().clone() for k, v in modelo.state_dict().items()},
                "target": {k: v.detach().cpu().clone() for k, v in alvo.state_dict().items()},
                "opt": opt.state_dict(),
                "eps": float(EPSILON),
                "lr": float(lr_now),
                "temp": float(temp_now),
            }

    # =========================================================
    # üîö Encerramento do epis√≥dio simbi√≥tico
    # =========================================================
    salvar_patrimonio_global(best_global)
    logging.info(f"\nüîÅ Epis√≥dio {episodio:04d} finalizado | cap_final={info.get('capital', 0):.2f} | best={best_global:.2f}\n")

    # =========================================================
    # üíÄ Fal√™ncia simbi√≥tica ‚Üí limpeza + warmup
    # =========================================================
    if info.get("capital", 0) <= 1.0:
        logging.info("üíÄ Fal√™ncia simbi√≥tica ‚Äî reiniciando ambiente")

        # üîª Limpeza de tensores √≥rf√£os e reset de scaler
        try:
            del last_good, loss, ema_q, ema_r
        except Exception:
            pass
        torch.cuda.empty_cache()
        gc.collect()
        if hasattr(scaler, "update"):
            scaler._enabled = False
            scaler = torch.amp.GradScaler(enabled=True)

        # ‚ôª Reset e warmup p√≥s-fal√™ncia
        s = env.reset()
        env.current_state = s
        try:
            with torch.inference_mode(), torch.cuda.amp.autocast():
                _ = modelo(torch.tensor(s, device=DEVICE).unsqueeze(0))
            torch.cuda.synchronize()
            logging.info("üî• Warmup CUDA p√≥s-fal√™ncia executado.")
        except Exception as e:
            logging.info(f"[WARN] Warmup p√≥s-fal√™ncia falhou: {e}")
